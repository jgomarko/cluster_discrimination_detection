{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Hidden Discrimination in the Adult Dataset\n",
    "This notebook demonstrates how to use the discrimination detection framework to identify and mitigate hidden discrimination in the Adult dataset.\n",
    "# Setup\n",
    "First, let's import all the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add the parent directory to the path to import our modules\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.preprocessing import load_adult_dataset, preprocess_adult_dataset\n",
    "from src.clustering import MultiClusteringAlgorithm\n",
    "from src.cmi import calculate_cmi, calculate_cmi_per_cluster, hierarchical_cmi_decomposition, interaction_information\n",
    "from src.validation import permutation_test, bootstrap_ci, plot_permutation_test, plot_bootstrap_distribution\n",
    "from src.mitigation import reweighting, FairnessRegularizedModel, subgroup_calibration, evaluate_mitigation, plot_mitigation_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and Preprocess Data\n",
    "Let's load the Adult dataset and preprocess it as described in the paper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (30162, 15)\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
      "0          2174             0              40  United-States       0  \n",
      "1             0             0              13  United-States       0  \n",
      "2             0             0              40  United-States       0  \n",
      "3             0             0              40  United-States       0  \n",
      "4             0             0              40           Cuba       0  \n",
      "Processed dataset shape: (30162, 96)\n",
      "Sensitive columns: ['sex', 'race']\n",
      "Outcome column: income\n"
     ]
    }
   ],
   "source": [
    "# Download Adult dataset if not already available\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "data_dir = '../data'\n",
    "adult_data_path = os.path.join(data_dir, 'adult.data')\n",
    "\n",
    "if not os.path.exists(adult_data_path):\n",
    "    print(\"Downloading Adult dataset...\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n",
    "        adult_data_path\n",
    "    )\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "# Load the dataset\n",
    "adult_data = load_adult_dataset(adult_data_path)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Dataset shape: {adult_data.shape}\")\n",
    "print(adult_data.head())\n",
    "\n",
    "# Preprocess the dataset\n",
    "processed_data, sensitive_columns, nonsensitive_columns, outcome_column = preprocess_adult_dataset(adult_data)\n",
    "\n",
    "print(f\"Processed dataset shape: {processed_data.shape}\")\n",
    "print(f\"Sensitive columns: {sensitive_columns}\")\n",
    "print(f\"Outcome column: {outcome_column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the distribution of the sensitive attributes and outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at distributions of sensitive attributes\n",
    "fig, axes = plt.subplots(1, len(sensitive_columns) + 1, figsize=(15, 5))\n",
    "\n",
    "for i, col in enumerate(sensitive_columns):\n",
    "    counts = processed_data[col].value_counts().sort_index()\n",
    "    axes[i].bar(counts.index, counts.values)\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].grid(alpha=0.3)\n",
    "    \n",
    "\n",
    "# Also show outcome distribution\n",
    "counts = processed_data[outcome_column].value_counts().sort_index()\n",
    "axes[-1].bar(counts.index, counts.values)\n",
    "axes[-1].set_title(f'Distribution of {outcome_column}')\n",
    "axes[-1].set_ylabel('Count')\n",
    "axes[-1].set_xticks([0, 1])\n",
    "axes[-1].set_xticklabels(['<=50K', '>50K'])\n",
    "axes[-1].grid(alpha=0.3)\n",
    "\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the relationship between sensitive attributes and outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create a figure to show relationship between sensitive attributes and outcome\n",
    "fig, axes = plt.subplots(1, len(sensitive_columns), figsize=(15, 5))\n",
    "\n",
    "for i, col in enumerate(sensitive_columns):\n",
    "    # Calculate outcome rate for each value of the sensitive attribute\n",
    "    group_outcomes = processed_data.groupby(col)[outcome_column].mean()\n",
    "    \n",
    "    axes[i].bar(group_outcomes.index, group_outcomes.values)\n",
    "    axes[i].set_title(f'Outcome Rate by {col}')\n",
    "    axes[i].set_ylabel('Probability of >50K')\n",
    "    axes[i].set_ylim(0, 1)\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Data and Perform Clustering\n",
    "Let's split the data into training and testing sets, then perform clustering on the non-sensitive attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 21113 samples\n",
      "Testing set: 9049 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X = processed_data[nonsensitive_columns]\n",
    "y = processed_data[outcome_column]\n",
    "sensitive = processed_data[sensitive_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
    "    X, y, sensitive, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Reconstruct DataFrames\n",
    "train_data = pd.concat([X_train, sensitive_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, sensitive_test, y_test], axis=1)\n",
    "\n",
    "print(f\"Training set: {len(train_data)} samples\")\n",
    "print(f\"Testing set: {len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try different clustering algorithms and find the optimal number of clusters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding optimal number of clusters using Gap statistic...\n",
      "Testing k=2...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Male'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m X_sample \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39msample(sample_size, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Find optimal k (using k-means for speed)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m optimal_k, gap_values \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mfind_optimal_k(\n\u001b[1;32m     11\u001b[0m     X_sample, \n\u001b[1;32m     12\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     13\u001b[0m     k_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m11\u001b[39m),\n\u001b[1;32m     14\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal number of clusters according to Gap statistic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimal_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Plot the Gap statistic\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Cluster_based/cluster_discrimination_detection/notebooks/../src/clustering/clustering.py:188\u001b[0m, in \u001b[0;36mMultiClusteringAlgorithm.find_optimal_k\u001b[0;34m(self, X, algorithm, k_range, random_state)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    187\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mk, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m--> 188\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(X)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    190\u001b[0m     gmm \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39mk, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1070\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1464\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \n\u001b[1;32m   1440\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1464\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1465\u001b[0m         X,\n\u001b[1;32m   1466\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1467\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[1;32m   1468\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1469\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_x,\n\u001b[1;32m   1470\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1475\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Male'"
     ]
    }
   ],
   "source": [
    "# Initialize the clustering algorithm\n",
    "clustering = MultiClusteringAlgorithm()\n",
    "\n",
    "# Try finding optimal number of clusters using the Gap statistic\n",
    "# Note: This can be time-consuming, so we'll use a subset of the data\n",
    "sample_size = min(10000, len(X_train))\n",
    "X_sample = X_train.sample(sample_size, random_state=42).values\n",
    "\n",
    "# Find optimal k (using k-means for speed)\n",
    "optimal_k, gap_values = clustering.find_optimal_k(\n",
    "    X_sample, \n",
    "    algorithm='kmeans', \n",
    "    k_range=range(2, 11),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Optimal number of clusters according to Gap statistic: {optimal_k}\")\n",
    "\n",
    "# Plot the Gap statistic\n",
    "clustering.plot_gap_statistic(range(2, 11), gap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the optimal number of clusters, let's compare different clustering algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying kmeans clustering...\n",
      "Error with kmeans: name 'optimal_k' is not defined\n",
      "\n",
      "Trying gmm clustering...\n",
      "Error with gmm: name 'optimal_k' is not defined\n",
      "\n",
      "Trying spectral clustering...\n",
      "Error with spectral: name 'optimal_k' is not defined\n",
      "\n",
      "Trying ensemble clustering...\n",
      "Error with ensemble: name 'optimal_k' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Try different clustering algorithms with the optimal k\n",
    "algorithms = ['kmeans', 'gmm', 'spectral', 'ensemble']\n",
    "cluster_results = {}\n",
    "cmi_values = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    print(f\"\\nTrying {algorithm} clustering...\")\n",
    "    try:\n",
    "        if algorithm == 'ensemble':\n",
    "            clusters = clustering.ensemble_clustering(X_train.values, n_clusters=optimal_k, random_state=42)\n",
    "        else:\n",
    "            clusters = clustering.fit(X_train.values, algorithm=algorithm, n_clusters=optimal_k, random_state=42)\n",
    "        \n",
    "        # Evaluate clustering quality\n",
    "        metrics = clustering.evaluate_clusters(X_train.values, clusters)\n",
    "        print(f\"Silhouette score: {metrics['silhouette_score']:.3f}\")\n",
    "        print(f\"Davies-Bouldin index: {metrics['davies_bouldin_index']:.3f}\")\n",
    "        \n",
    "        # Calculate CMI\n",
    "        cmi = calculate_cmi(\n",
    "            train_data, \n",
    "            clusters, \n",
    "            sensitive_columns, \n",
    "            outcome_column, \n",
    "            nonsensitive_columns\n",
    "        )\n",
    "        print(f\"CMI: {cmi:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        cluster_results[algorithm] = clusters\n",
    "        cmi_values[algorithm] = cmi\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {algorithm}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the clusters from the best algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the algorithm with the highest CMI (best at revealing discrimination)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_algorithm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(cmi_values, key\u001b[38;5;241m=\u001b[39mcmi_values\u001b[38;5;241m.\u001b[39mget)\n\u001b[1;32m      3\u001b[0m best_clusters \u001b[38;5;241m=\u001b[39m cluster_results[best_algorithm]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest algorithm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with CMI = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcmi_values[best_algorithm]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: max() iterable argument is empty"
     ]
    }
   ],
   "source": [
    "# Find the algorithm with the highest CMI (best at revealing discrimination)\n",
    "best_algorithm = max(cmi_values, key=cmi_values.get)\n",
    "best_clusters = cluster_results[best_algorithm]\n",
    "\n",
    "print(f\"Best algorithm: {best_algorithm} with CMI = {cmi_values[best_algorithm]:.4f}\")\n",
    "\n",
    "# Visualize the clusters using PCA\n",
    "clustering.plot_clusters(X_train.values, best_clusters)\n",
    "\n",
    "# Also visualize with sensitive attributes coloring\n",
    "if 'sex' in sensitive_columns:\n",
    "    clustering.plot_clusters(\n",
    "        X_train.values, \n",
    "        best_clusters, \n",
    "        sensitive_attr=sensitive_train['sex'].values\n",
    "    )\n",
    "\n",
    "if 'race' in sensitive_columns:\n",
    "    clustering.plot_clusters(\n",
    "        X_train.values, \n",
    "        best_clusters, \n",
    "        sensitive_attr=sensitive_train['race'].values\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate CMI and Identify High-Discrimination Clusters\n",
    "Now, let's calculate the CMI for each cluster to identify ones with high discrimination:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CMI for each cluster...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate CMI per cluster\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating CMI for each cluster...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m cmi_per_cluster \u001b[38;5;241m=\u001b[39m calculate_cmi_per_cluster(\n\u001b[1;32m      4\u001b[0m     train_data,\n\u001b[0;32m----> 5\u001b[0m     best_clusters,\n\u001b[1;32m      6\u001b[0m     sensitive_columns,\n\u001b[1;32m      7\u001b[0m     outcome_column,\n\u001b[1;32m      8\u001b[0m     nonsensitive_columns\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Add clusters to training data for further analysis\u001b[39;00m\n\u001b[1;32m     12\u001b[0m train_data_with_clusters \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate CMI per cluster\n",
    "print(\"Calculating CMI for each cluster...\")\n",
    "cmi_per_cluster = calculate_cmi_per_cluster(\n",
    "    train_data,\n",
    "    best_clusters,\n",
    "    sensitive_columns,\n",
    "    outcome_column,\n",
    "    nonsensitive_columns\n",
    ")\n",
    "\n",
    "# Add clusters to training data for further analysis\n",
    "train_data_with_clusters = train_data.copy()\n",
    "train_data_with_clusters['cluster'] = best_clusters\n",
    "\n",
    "# Plot CMI by cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "clusters = list(cmi_per_cluster.keys())\n",
    "cmi_values_list = list(cmi_per_cluster.values())\n",
    "\n",
    "# Sort by CMI value\n",
    "sorted_indices = np.argsort(cmi_values_list)[::-1]\n",
    "sorted_clusters = [clusters[i] for i in sorted_indices]\n",
    "sorted_values = [cmi_values_list[i] for i in sorted_indices]\n",
    "\n",
    "plt.bar(sorted_clusters, sorted_values)\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('CMI')\n",
    "plt.title('Conditional Mutual Information by Cluster')\n",
    "plt.xticks(sorted_clusters)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Identify high-discrimination clusters\n",
    "threshold = np.mean(list(cmi_per_cluster.values())) + 0.5 * np.std(list(cmi_per_cluster.values()))\n",
    "high_discrim_clusters = [c for c, v in cmi_per_cluster.items() if v > threshold]\n",
    "\n",
    "print(\"\\nCMI per cluster:\")\n",
    "for cluster_id, cluster_cmi in sorted(cmi_per_cluster.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  Cluster {cluster_id}: {cluster_cmi:.4f}\" + \n",
    "          (\" (high discrimination)\" if cluster_id in high_discrim_clusters else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmi_per_cluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot CMI by cluster\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cmi_per_cluster\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m cmi_values_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cmi_per_cluster\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Sort by CMI value\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cmi_per_cluster' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot CMI by cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "clusters = list(cmi_per_cluster.keys())\n",
    "cmi_values_list = list(cmi_per_cluster.values())\n",
    "\n",
    "# Sort by CMI value\n",
    "sorted_indices = np.argsort(cmi_values_list)[::-1]\n",
    "sorted_clusters = [clusters[i] for i in sorted_indices]\n",
    "sorted_values = [cmi_values_list[i] for i in sorted_indices]\n",
    "\n",
    "# Define discrimination thresholds\n",
    "high_threshold = 0.1\n",
    "medium_threshold = 0.05\n",
    "\n",
    "# Color bars based on discrimination level\n",
    "colors = ['red' if val > high_threshold else 'orange' if val > medium_threshold else 'blue' for val in sorted_values]\n",
    "\n",
    "# Create bar chart with colors\n",
    "bars = plt.bar(sorted_clusters, sorted_values, color=colors)\n",
    "\n",
    "# Add threshold lines\n",
    "plt.axhline(y=high_threshold, color='red', linestyle='--', label='High discrimination (0.1)')\n",
    "plt.axhline(y=medium_threshold, color='orange', linestyle='--', label='Medium discrimination (0.05)')\n",
    "\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('CMI')\n",
    "plt.title('Discrimination Level by Cluster')\n",
    "plt.xticks(sorted_clusters)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('discrimination_by_cluster.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Identify high-discrimination clusters\n",
    "print(\"\\nCMI per cluster:\")\n",
    "for cluster_id, cluster_cmi in sorted(cmi_per_cluster.items(), key=lambda x: x[1], reverse=True):\n",
    "    discrimination_level = \"high discrimination\" if cluster_cmi > high_threshold else \\\n",
    "                          \"medium discrimination\" if cluster_cmi > medium_threshold else \\\n",
    "                          \"low discrimination\"\n",
    "    print(f\"  Cluster {cluster_id}: {cluster_cmi:.4f} ({discrimination_level})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the characteristics of high-discrimination clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_discrim_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster_id \u001b[38;5;129;01min\u001b[39;00m high_discrim_clusters:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCluster \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m characteristics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     cluster_data \u001b[38;5;241m=\u001b[39m train_data_with_clusters[train_data_with_clusters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m cluster_id]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'high_discrim_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "for cluster_id in high_discrim_clusters:\n",
    "    print(f\"\\nCluster {cluster_id} characteristics:\")\n",
    "    cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == cluster_id]\n",
    "    \n",
    "    # Outcome rate\n",
    "    outcome_rate = cluster_data[outcome_column].mean()\n",
    "    print(f\"  Outcome rate: {outcome_rate:.2f}\")\n",
    "    print(f\"  Size: {len(cluster_data)} samples\")\n",
    "    \n",
    "    # Distribution by sensitive attributes\n",
    "    for col in sensitive_columns:\n",
    "        print(f\"\\n  Distribution by {col}:\")\n",
    "        value_counts = cluster_data[col].value_counts(normalize=True)\n",
    "        \n",
    "        for value, proportion in value_counts.items():\n",
    "            # Get outcome rate for this subgroup\n",
    "            subgroup = cluster_data[cluster_data[col] == value]\n",
    "            subgroup_outcome_rate = subgroup[outcome_column].mean()\n",
    "            \n",
    "            print(f\"    {col}={value}: {proportion:.2f} of cluster, outcome rate: {subgroup_outcome_rate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_discrim_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster_id \u001b[38;5;129;01min\u001b[39;00m high_discrim_clusters:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLUSTER \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DETAILED ANALYSIS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'high_discrim_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "for cluster_id in high_discrim_clusters:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"CLUSTER {cluster_id} DETAILED ANALYSIS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Get data for this cluster\n",
    "    cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == cluster_id]\n",
    "    \n",
    "    # Basic cluster statistics\n",
    "    outcome_rate = cluster_data[outcome_column].mean()\n",
    "    cluster_size = len(cluster_data)\n",
    "    cluster_percentage = (cluster_size / len(train_data_with_clusters)) * 100\n",
    "    \n",
    "    print(f\"Size: {cluster_size} samples ({cluster_percentage:.1f}% of total data)\")\n",
    "    print(f\"Overall outcome rate: {outcome_rate:.2f}\")\n",
    "    \n",
    "    # CMI value for this cluster\n",
    "    cluster_cmi = cmi_per_cluster.get(cluster_id, \"Not calculated\")\n",
    "    print(f\"Discrimination level (CMI): {cluster_cmi:.4f}\")\n",
    "    \n",
    "    # Analyze individual sensitive attributes\n",
    "    print(\"\\nSENSITIVE ATTRIBUTE ANALYSIS:\")\n",
    "    for col in sensitive_columns:\n",
    "        print(f\"\\n  Distribution by {col}:\")\n",
    "        value_counts = cluster_data[col].value_counts()\n",
    "        total = value_counts.sum()\n",
    "        \n",
    "        # Calculate divergence from overall outcome rate\n",
    "        max_divergence = 0\n",
    "        max_divergence_group = None\n",
    "        \n",
    "        # Create a formatted table for output\n",
    "        print(f\"    {'Value':<15} {'Count':<8} {'Proportion':<12} {'Outcome Rate':<15} {'Divergence':<10}\")\n",
    "        print(f\"    {'-'*60}\")\n",
    "        \n",
    "        for value, count in value_counts.items():\n",
    "            proportion = count / total\n",
    "            subgroup = cluster_data[cluster_data[col] == value]\n",
    "            subgroup_outcome_rate = subgroup[outcome_column].mean()\n",
    "            divergence = abs(subgroup_outcome_rate - outcome_rate)\n",
    "            \n",
    "            # Track maximum divergence\n",
    "            if divergence > max_divergence:\n",
    "                max_divergence = divergence\n",
    "                max_divergence_group = value\n",
    "                \n",
    "            # Format and print the row\n",
    "            print(f\"    {str(value):<15} {count:<8} {proportion:.2f} ({proportion*100:.1f}%) {subgroup_outcome_rate:.2f} {divergence:+.2f}\")\n",
    "        \n",
    "        print(f\"\\n  → Highest divergence in {col}: {max_divergence_group} ({max_divergence:+.2f})\")\n",
    "    \n",
    "    # Intersectional analysis\n",
    "    if len(sensitive_columns) > 1:\n",
    "        print(\"\\nINTERSECTIONAL ANALYSIS:\")\n",
    "        # Create intersection column\n",
    "        cluster_data['intersection'] = cluster_data[sensitive_columns].apply(\n",
    "            lambda row: '_'.join(str(row[col]) for col in sensitive_columns), axis=1\n",
    "        )\n",
    "        \n",
    "        # Get intersectional counts and rates\n",
    "        intersection_counts = cluster_data['intersection'].value_counts()\n",
    "        \n",
    "        # Only show intersections with at least 20 samples (for statistical reliability)\n",
    "        threshold = 20\n",
    "        valid_intersections = intersection_counts[intersection_counts >= threshold]\n",
    "        \n",
    "        if len(valid_intersections) > 0:\n",
    "            print(f\"\\n  Showing intersections with at least {threshold} samples:\")\n",
    "            print(f\"    {'Intersection':<25} {'Count':<8} {'Proportion':<12} {'Outcome Rate':<15} {'Divergence':<10}\")\n",
    "            print(f\"    {'-'*70}\")\n",
    "            \n",
    "            for intersection, count in valid_intersections.items():\n",
    "                proportion = count / total\n",
    "                subgroup = cluster_data[cluster_data['intersection'] == intersection]\n",
    "                subgroup_outcome_rate = subgroup[outcome_column].mean()\n",
    "                divergence = subgroup_outcome_rate - outcome_rate\n",
    "                \n",
    "                print(f\"    {intersection:<25} {count:<8} {proportion:.2f} ({proportion*100:.1f}%) {subgroup_outcome_rate:.2f} {divergence:+.2f}\")\n",
    "        else:\n",
    "            print(f\"  No intersections with at least {threshold} samples found.\")\n",
    "    \n",
    "    # Feature importance for this cluster\n",
    "    print(\"\\nKEY FEATURES CHARACTERIZING THIS CLUSTER:\")\n",
    "    # Get all non-sensitive columns except the outcome and cluster columns\n",
    "    feature_columns = [col for col in cluster_data.columns \n",
    "                      if col not in sensitive_columns + [outcome_column, 'cluster', 'intersection']]\n",
    "    \n",
    "    # Calculate the mean value of each feature in this cluster vs. overall\n",
    "    feature_comparison = []\n",
    "    for col in feature_columns:\n",
    "        try:\n",
    "            # Only analyze numerical columns\n",
    "            if pd.api.types.is_numeric_dtype(cluster_data[col]):\n",
    "                cluster_mean = cluster_data[col].mean()\n",
    "                overall_mean = train_data_with_clusters[col].mean()\n",
    "                std_dev = train_data_with_clusters[col].std()\n",
    "                \n",
    "                # Calculate z-score to measure how distinctive this feature is\n",
    "                if std_dev > 0:\n",
    "                    z_score = (cluster_mean - overall_mean) / std_dev\n",
    "                    feature_comparison.append((col, cluster_mean, overall_mean, z_score))\n",
    "        except:\n",
    "            # Skip columns that cause errors\n",
    "            continue\n",
    "    \n",
    "    # Sort by absolute z-score and display top features\n",
    "    top_n = min(10, len(feature_comparison))\n",
    "    feature_comparison.sort(key=lambda x: abs(x[3]), reverse=True)\n",
    "    \n",
    "    if feature_comparison:\n",
    "        print(f\"  Top {top_n} distinctive features:\")\n",
    "        print(f\"    {'Feature':<20} {'Cluster Mean':<15} {'Overall Mean':<15} {'Z-Score':<10}\")\n",
    "        print(f\"    {'-'*60}\")\n",
    "        \n",
    "        for i in range(top_n):\n",
    "            col, c_mean, o_mean, z = feature_comparison[i]\n",
    "            print(f\"    {col:<20} {c_mean:.2f} {o_mean:.2f} {z:+.2f}\")\n",
    "    else:\n",
    "        print(\"  No numerical features available for analysis.\")\n",
    "    \n",
    "    print(f\"\\n{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "\n",
    "# Create a figure for comparison of all high discrimination clusters\n",
    "fig_overview = plt.figure(figsize=(10, 6))\n",
    "ax_overview = fig_overview.add_subplot(111)\n",
    "\n",
    "# Prepare data for overview comparison\n",
    "cluster_summary = []\n",
    "\n",
    "# Loop through each high discrimination cluster\n",
    "for cluster_id in high_discrim_clusters:\n",
    "    cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == cluster_id]\n",
    "    \n",
    "    # Outcome rate\n",
    "    outcome_rate = cluster_data[outcome_column].mean()\n",
    "    print(f\"\\nCluster {cluster_id} characteristics:\")\n",
    "    print(f\"  Outcome rate: {outcome_rate:.2f}\")\n",
    "    print(f\"  Size: {len(cluster_data)} samples\")\n",
    "    \n",
    "    # Store summary data for overview plot\n",
    "    cluster_summary.append({\n",
    "        'cluster_id': cluster_id,\n",
    "        'size': len(cluster_data),\n",
    "        'outcome_rate': outcome_rate\n",
    "    })\n",
    "    \n",
    "    # Create a figure for this cluster's detailed analysis\n",
    "    fig, axes = plt.subplots(len(sensitive_columns), 2, figsize=(15, 4 * len(sensitive_columns)))\n",
    "    fig.suptitle(f'Cluster {cluster_id} Characteristics (Size: {len(cluster_data)} samples, Overall outcome rate: {outcome_rate:.2f})', \n",
    "                fontsize=16)\n",
    "    \n",
    "    # Analyze each sensitive attribute\n",
    "    for idx, col in enumerate(sensitive_columns):\n",
    "        print(f\"\\n  Distribution by {col}:\")\n",
    "        \n",
    "        # Get value counts and prepare visualization data\n",
    "        value_counts = cluster_data[col].value_counts(normalize=True)\n",
    "        subgroup_stats = []\n",
    "        \n",
    "        for value, proportion in value_counts.items():\n",
    "            # Get outcome rate for this subgroup\n",
    "            subgroup = cluster_data[cluster_data[col] == value]\n",
    "            subgroup_outcome_rate = subgroup[outcome_column].mean()\n",
    "            \n",
    "            print(f\"    {col}={value}: {proportion:.2f} of cluster, outcome rate: {subgroup_outcome_rate:.2f}\")\n",
    "            \n",
    "            # Store for plotting\n",
    "            subgroup_stats.append({\n",
    "                'value': str(value),\n",
    "                'proportion': proportion,\n",
    "                'outcome_rate': subgroup_outcome_rate,\n",
    "                'size': len(subgroup)\n",
    "            })\n",
    "        \n",
    "        # Convert to DataFrame for easier plotting\n",
    "        subgroup_df = pd.DataFrame(subgroup_stats)\n",
    "        \n",
    "        # Left plot: Distribution within cluster by sensitive attribute\n",
    "        if len(sensitive_columns) == 1:\n",
    "            ax1 = axes[0]\n",
    "            ax2 = axes[1]\n",
    "        else:\n",
    "            ax1 = axes[idx, 0]\n",
    "            ax2 = axes[idx, 1]\n",
    "            \n",
    "        # Create horizontal bar chart for distribution\n",
    "        bars = ax1.barh(subgroup_df['value'], subgroup_df['proportion'], color='skyblue')\n",
    "        ax1.set_title(f'Distribution by {col}')\n",
    "        ax1.set_xlabel('Proportion within cluster')\n",
    "        ax1.set_xlim(0, 1)\n",
    "        \n",
    "        # Add proportion labels\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{width:.2f}', va='center')\n",
    "        \n",
    "        # Right plot: Outcome rates by subgroup\n",
    "        bars = ax2.barh(subgroup_df['value'], subgroup_df['outcome_rate'], color='lightcoral')\n",
    "        ax2.set_title(f'Outcome Rates by {col}')\n",
    "        ax2.set_xlabel(f'{outcome_column} Rate')\n",
    "        ax2.set_xlim(0, 1)\n",
    "        \n",
    "        # Add outcome rate labels and sample size\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            ax2.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{width:.2f} (n={subgroup_df.iloc[i][\"size\"]})', va='center')\n",
    "        \n",
    "        # Add a reference line for the overall cluster outcome rate\n",
    "        ax2.axvline(x=outcome_rate, color='red', linestyle='--', \n",
    "                   label=f'Cluster average: {outcome_rate:.2f}')\n",
    "        ax2.legend()\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to make room for the title\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f'cluster_{cluster_id}_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Create overview plot comparing all high discrimination clusters\n",
    "cluster_df = pd.DataFrame(cluster_summary)\n",
    "\n",
    "# Sort by outcome rate for better visualization\n",
    "cluster_df = cluster_df.sort_values('outcome_rate', ascending=False)\n",
    "\n",
    "# Plot comparisons\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('High Discrimination Clusters Comparison', fontsize=16)\n",
    "\n",
    "# Left: Cluster sizes\n",
    "size_bars = ax1.bar([f'Cluster {cid}' for cid in cluster_df['cluster_id']], \n",
    "                    cluster_df['size'], color='lightblue')\n",
    "ax1.set_title('Cluster Sizes')\n",
    "ax1.set_xlabel('Cluster')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "\n",
    "# Add size labels\n",
    "for bar in size_bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, height + 5, \n",
    "            f'{int(height)}', ha='center')\n",
    "\n",
    "# Right: Outcome rates\n",
    "rate_bars = ax2.bar([f'Cluster {cid}' for cid in cluster_df['cluster_id']], \n",
    "                   cluster_df['outcome_rate'], color='salmon')\n",
    "ax2.set_title(f'{outcome_column} Rates')\n",
    "ax2.set_xlabel('Cluster')\n",
    "ax2.set_ylabel('Rate')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Add rate labels\n",
    "for bar in rate_bars:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, height + 0.01, \n",
    "            f'{height:.2f}', ha='center')\n",
    "\n",
    "# Overall dataset average for reference\n",
    "overall_rate = train_data_with_clusters[outcome_column].mean()\n",
    "ax2.axhline(y=overall_rate, color='red', linestyle='--', \n",
    "           label=f'Dataset average: {overall_rate:.2f}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save the overview comparison figure\n",
    "plt.savefig('high_discrimination_clusters_comparison.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Statistical Validation\n",
    "Let's validate our findings for one of the high-discrimination clusters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_discrim_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pick the cluster with the highest CMI\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m high_discrim_clusters:\n\u001b[1;32m      3\u001b[0m     target_cluster \u001b[38;5;241m=\u001b[39m high_discrim_clusters[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Extract data for this cluster\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'high_discrim_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "# Pick the cluster with the highest CMI\n",
    "if high_discrim_clusters:\n",
    "    target_cluster = high_discrim_clusters[0]\n",
    "    \n",
    "    # Extract data for this cluster\n",
    "    cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == target_cluster]\n",
    "    cluster_size = len(cluster_data)\n",
    "    \n",
    "    print(f\"Validating discrimination in cluster {target_cluster} (size: {cluster_size})...\")\n",
    "    \n",
    "    # Set all samples to same cluster (since we're analyzing within a single cluster)\n",
    "    cluster_assignments = np.zeros(cluster_size)\n",
    "    \n",
    "    # Perform permutation test\n",
    "    print(\"\\nPerforming permutation test...\")\n",
    "    perm_results = permutation_test(\n",
    "        cluster_data,\n",
    "        cluster_assignments,\n",
    "        sensitive_columns,\n",
    "        outcome_column,\n",
    "        nonsensitive_columns,\n",
    "        num_permutations=100  # Use more (e.g., 1000) for a real analysis\n",
    "    )\n",
    "    \n",
    "    # Plot permutation test results\n",
    "    plot_permutation_test(perm_results)\n",
    "   \n",
    "  \n",
    "\n",
    "    \n",
    "    # Bootstrap confidence interval\n",
    "    print(\"\\nCalculating bootstrap confidence interval...\")\n",
    "    bootstrap_results = bootstrap_ci(\n",
    "        cluster_data,\n",
    "        cluster_assignments,\n",
    "        sensitive_columns,\n",
    "        outcome_column,\n",
    "        nonsensitive_columns,\n",
    "        num_bootstraps=1000  # Use more (e.g., 1000) for a real analysis\n",
    "    )\n",
    "    # Save bootstrap CI plot\n",
    "    plot_bootstrap_distribution(bootstrap_results)\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(f'cluster_{target_cluster}_bootstrap_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "\n",
    "    # Plot bootstrap distribution\n",
    "    plot_bootstrap_distribution(bootstrap_results)\n",
    "else:\n",
    "    print(\"No high-discrimination clusters identified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_discrim_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pick the cluster with the highest CMI\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m high_discrim_clusters:\n\u001b[1;32m      3\u001b[0m     target_cluster \u001b[38;5;241m=\u001b[39m high_discrim_clusters[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Extract data for this cluster\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'high_discrim_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "# Pick the cluster with the highest CMI\n",
    "if high_discrim_clusters:\n",
    "    target_cluster = high_discrim_clusters[0]\n",
    "    \n",
    "    # Extract data for this cluster\n",
    "    cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == target_cluster]\n",
    "    cluster_size = len(cluster_data)\n",
    "    \n",
    "    print(f\"Validating discrimination in cluster {target_cluster} (size: {cluster_size})...\")\n",
    "    \n",
    "    # Set all samples to same cluster (since we're analyzing within a single cluster)\n",
    "    cluster_assignments = np.zeros(cluster_size)\n",
    "    \n",
    "    # Perform permutation test\n",
    "    print(\"\\nPerforming permutation test...\")\n",
    "    perm_results = permutation_test(\n",
    "        cluster_data,\n",
    "        cluster_assignments,\n",
    "        sensitive_columns,\n",
    "        outcome_column,\n",
    "        nonsensitive_columns,\n",
    "        num_permutations=100  # Use more (e.g., 1000) for a real analysis\n",
    "    )\n",
    "    \n",
    "    # Plot permutation test results and save\n",
    "    # Assuming plot_permutation_test doesn't return a figure but creates one\n",
    "    plot_permutation_test(perm_results)\n",
    "    plt.savefig(f'cluster_{target_cluster}_permutation_test.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Bootstrap confidence interval\n",
    "    print(\"\\nCalculating bootstrap confidence interval...\")\n",
    "    bootstrap_results = bootstrap_ci(\n",
    "        cluster_data,\n",
    "        cluster_assignments,\n",
    "        sensitive_columns,\n",
    "        outcome_column,\n",
    "        nonsensitive_columns,\n",
    "        num_bootstraps=1000  # Use more (e.g., 1000) for a real analysis\n",
    "    )\n",
    "    \n",
    "    # Plot bootstrap distribution and save\n",
    "    # Assuming plot_bootstrap_distribution doesn't return a figure but creates one\n",
    "    plot_bootstrap_distribution(bootstrap_results)\n",
    "    plt.savefig(f'cluster_{target_cluster}_bootstrap_ci.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create and save a combined visualization showing key metrics\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Extract p-value and observed CMI from permutation results\n",
    "    p_value = perm_results['p_value']\n",
    "    observed_cmi = perm_results['observed_cmi']\n",
    "    \n",
    "    # Handle different possible formats of bootstrap_results\n",
    "    # Check the structure of bootstrap_results\n",
    "    if isinstance(bootstrap_results, dict) and 'ci' in bootstrap_results:\n",
    "        lower_ci, upper_ci = bootstrap_results['ci']\n",
    "    elif isinstance(bootstrap_results, dict) and 'lower_ci' in bootstrap_results and 'upper_ci' in bootstrap_results:\n",
    "        lower_ci = bootstrap_results['lower_ci']\n",
    "        upper_ci = bootstrap_results['upper_ci']\n",
    "    elif isinstance(bootstrap_results, tuple) and len(bootstrap_results) == 2:\n",
    "        lower_ci, upper_ci = bootstrap_results\n",
    "    else:\n",
    "        # If we can't determine the CI, use observed value with a default margin\n",
    "        print(\"Warning: Could not extract CI from bootstrap results. Using default CI.\")\n",
    "        lower_ci = observed_cmi * 0.9\n",
    "        upper_ci = observed_cmi * 1.1\n",
    "    \n",
    "    # Create summary visualization\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(['Observed CMI'], [observed_cmi], color='blue')\n",
    "    plt.title(f'Observed CMI: {observed_cmi:.4f}')\n",
    "    plt.ylabel('CMI Value')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.bar(['P-value'], [p_value], color='red' if p_value < 0.05 else 'green')\n",
    "    plt.title(f'Permutation Test P-value: {p_value:.4f}')\n",
    "    plt.axhline(y=0.05, color='r', linestyle='--', label='Significance threshold')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.errorbar(['CMI 95% CI'], [observed_cmi], yerr=[[observed_cmi-lower_ci], [upper_ci-observed_cmi]], \n",
    "                fmt='o', capsize=10, color='purple')\n",
    "    plt.title(f'Bootstrap 95% CI: [{lower_ci:.4f}, {upper_ci:.4f}]')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    # Show cluster info\n",
    "    cluster_info = (f\"Cluster {target_cluster}\\n\"\n",
    "                   f\"Size: {cluster_size} samples\\n\"\n",
    "                   f\"Outcome rate: {cluster_data[outcome_column].mean():.2f}\\n\"\n",
    "                   f\"Significant: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "    plt.text(0.5, 0.5, cluster_info, ha='center', va='center', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Discrimination Validation for Cluster {target_cluster}', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    \n",
    "    # Save the summary figure\n",
    "    plt.savefig(f'cluster_{target_cluster}_validation_summary.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No high-discrimination clusters identified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hierarchical Decomposition and Interaction Analysis\n",
    "Let's analyze which sensitive attributes contribute most to discrimination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_discrim_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m high_discrim_clusters:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHierarchical CMI decomposition for high-discrimination clusters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cluster_id \u001b[38;5;129;01min\u001b[39;00m high_discrim_clusters:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'high_discrim_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "if high_discrim_clusters:\n",
    "    print(\"Hierarchical CMI decomposition for high-discrimination clusters:\")\n",
    "    \n",
    "    for cluster_id in high_discrim_clusters:\n",
    "        cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == cluster_id]\n",
    "        \n",
    "        contributions = hierarchical_cmi_decomposition(\n",
    "            cluster_data,\n",
    "            np.zeros(len(cluster_data)),  # All in same cluster\n",
    "            sensitive_columns,\n",
    "            outcome_column,\n",
    "            nonsensitive_columns\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nCluster {cluster_id} contributions:\")\n",
    "        cluster_cmi = cmi_per_cluster[cluster_id]\n",
    "        \n",
    "        # Create a bar chart of contributions\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        attrs = list(contributions.keys())\n",
    "        contrib_values = list(contributions.values())\n",
    "        percentages = [value/cluster_cmi*100 for value in contrib_values]\n",
    "        \n",
    "        plt.bar(attrs, percentages)\n",
    "        plt.xlabel('Sensitive Attribute')\n",
    "        plt.ylabel('Contribution (%)')\n",
    "        plt.title(f'Attribute Contributions to CMI in Cluster {cluster_id}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.ylim(0, 100)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, p in enumerate(percentages):\n",
    "            plt.annotate(f'{p:.1f}%', \n",
    "                        (i, p), \n",
    "                        ha='center', va='bottom')\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(f'cluster_{cluster_id}_contributions.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()  # Keep the show command if you still want to display it\n",
    "        \n",
    "        # Print textual results\n",
    "        for attr, value in contributions.items():\n",
    "            print(f\"  {attr}: {value:.4f} ({value/cluster_cmi*100:.1f}%)\")\n",
    "        \n",
    "    # Interaction information (if there are at least 2 sensitive attributes)\n",
    "    if len(sensitive_columns) >= 2:\n",
    "        print(\"\\nInteraction information for high-discrimination clusters:\")\n",
    "        \n",
    "        for cluster_id in high_discrim_clusters:\n",
    "            cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == cluster_id]\n",
    "            \n",
    "            interaction = interaction_information(\n",
    "                cluster_data,\n",
    "                np.zeros(len(cluster_data)),  # All in same cluster\n",
    "                sensitive_columns[0],\n",
    "                sensitive_columns[1],\n",
    "                outcome_column,\n",
    "                nonsensitive_columns\n",
    "            )\n",
    "            \n",
    "            # Create visualization for interaction information\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.bar(['Interaction Information'], [interaction])\n",
    "            plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "            \n",
    "            effect_type = \"Synergistic\" if interaction > 0 else \"Redundant\"\n",
    "            plt.title(f'{effect_type} Effect in Cluster {cluster_id}')\n",
    "            plt.ylabel('Interaction Information')\n",
    "            plt.annotate(f'{interaction:.4f}', \n",
    "                        (0, interaction), \n",
    "                        ha='center', \n",
    "                        va='bottom' if interaction > 0 else 'top')\n",
    "            \n",
    "            # Save the interaction visualization\n",
    "            plt.savefig(f'cluster_{cluster_id}_interaction.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()  # Keep the show command if you still want to display it\n",
    "            \n",
    "            print(f\"\\nCluster {cluster_id}:\")\n",
    "            print(f\"  Interaction information: {interaction:.4f}\")\n",
    "            effect_type = \"Synergistic\" if interaction > 0 else \"Redundant\"\n",
    "            print(f\"  {effect_type} effect between {sensitive_columns[0]} and {sensitive_columns[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Mitigation \n",
    "Now, let's apply mitigation strategies to reduce the detected discrimination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying reweighting strategy...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying reweighting strategy...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m reweighted_data \u001b[38;5;241m=\u001b[39m reweighting(train_data, best_clusters, sensitive_columns, outcome_column)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Visualize weight distribution\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Applying reweighting strategy...\")\n",
    "reweighted_data = reweighting(train_data, best_clusters, sensitive_columns, outcome_column)\n",
    "\n",
    "# Visualize weight distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(reweighted_data['weight'], bins=30)\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Weights after Reweighting')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a model with fairness regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with fairness regularization...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model with fairness regularization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m fair_model \u001b[38;5;241m=\u001b[39m FairnessRegularizedModel(lambda_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m fair_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, sensitive_train, best_clusters, nonsensitive_columns)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Make predictions on test set\u001b[39;00m\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m fair_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "# Train model with fairness regularization\n",
    "print(\"Training model with fairness regularization...\")\n",
    "fair_model = FairnessRegularizedModel(lambda_param=1.0)\n",
    "fair_model.fit(X_train, y_train, sensitive_train, best_clusters, nonsensitive_columns)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = fair_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply subgroup-specific calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying subgroup-specific calibration...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m train_data_for_calibration \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m train_data_for_calibration\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m----> 9\u001b[0m     train_data_for_calibration[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m best_clusters\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     calibration_results \u001b[38;5;241m=\u001b[39m subgroup_calibration(\n\u001b[1;32m     13\u001b[0m         train_data_for_calibration, \n\u001b[1;32m     14\u001b[0m         best_clusters, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         base_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply subgroup calibration\n",
    "print(\"Applying subgroup-specific calibration...\")\n",
    "# First make sure the outcome column is explicitly identified\n",
    "outcome_column_name = y_train.name if hasattr(y_train, 'name') else outcome_column\n",
    "\n",
    "# Make sure train_data has all the necessary columns\n",
    "train_data_for_calibration = train_data.copy()\n",
    "if 'cluster' not in train_data_for_calibration.columns:\n",
    "    train_data_for_calibration['cluster'] = best_clusters\n",
    "\n",
    "try:\n",
    "    calibration_results = subgroup_calibration(\n",
    "        train_data_for_calibration, \n",
    "        best_clusters, \n",
    "        sensitive_columns,\n",
    "        # You can optionally provide a base model here\n",
    "        base_model=None\n",
    "    )\n",
    "    \n",
    "    # Print performances by subgroup\n",
    "    print(\"\\nCalibration performance by subgroup:\")\n",
    "    \n",
    "    if 'performance' in calibration_results and calibration_results['performance']:\n",
    "        performances = calibration_results['performance']\n",
    "        \n",
    "        # Sort by improvement\n",
    "        improvements = [(key, perf['calibrated_acc'] - perf['base_acc']) \n",
    "                       for key, perf in performances.items()]\n",
    "        improvements.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for key, improvement in improvements:\n",
    "            perf = performances[key]\n",
    "            print(f\"  {key}: {perf['base_acc']:.4f} -> {perf['calibrated_acc']:.4f} \" + \n",
    "                  f\"({improvement*100:+.2f}%, {perf['samples']} samples)\")\n",
    "    else:\n",
    "        print(\"No performance metrics available. This may be due to insufficient samples in subgroups.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during calibration: {str(e)}\")\n",
    "    print(\"\\nFalling back to simple model comparison without calibration...\")\n",
    "    \n",
    "    # Train a regular model for comparison\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    regular_model = LogisticRegression(max_iter=1000)\n",
    "    regular_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Train a weighted model using reweighting\n",
    "    weighted_data = reweighting(train_data, best_clusters, sensitive_columns, outcome_column_name)\n",
    "    weighted_model = LogisticRegression(max_iter=1000)\n",
    "    weighted_model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        sample_weight=weighted_data['weight'].values if 'weight' in weighted_data.columns else None\n",
    "    )\n",
    "    \n",
    "    # Compare on test set\n",
    "    regular_preds = regular_model.predict(X_test)\n",
    "    weighted_preds = weighted_model.predict(X_test)\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(f\"Regular model accuracy: {accuracy_score(y_test, regular_preds):.4f}\")\n",
    "    print(f\"Weighted model accuracy: {accuracy_score(y_test, weighted_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate Mitigation Effectiveness\n",
    "Finally, let's evaluate how effective our mitigation strategies were at reducing discrimination:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NearestCentroid\n\u001b[1;32m      6\u001b[0m centroid_classifier \u001b[38;5;241m=\u001b[39m NearestCentroid()\n\u001b[0;32m----> 7\u001b[0m centroid_classifier\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mvalues, best_clusters)\n\u001b[1;32m      8\u001b[0m test_clusters \u001b[38;5;241m=\u001b[39m centroid_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      9\u001b[0m test_data_with_clusters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_clusters\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "# Create test data with original and fair predictions\n",
    "test_data_with_clusters = test_data.copy()\n",
    "\n",
    "# Get clusters for test data (using nearest centroid)\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "centroid_classifier = NearestCentroid()\n",
    "centroid_classifier.fit(X_train.values, best_clusters)\n",
    "test_clusters = centroid_classifier.predict(X_test.values)\n",
    "test_data_with_clusters['cluster'] = test_clusters\n",
    "\n",
    "# Get predictions from a regular model for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regular_model = LogisticRegression(max_iter=1000)\n",
    "regular_model.fit(X_train, y_train)\n",
    "regular_preds = regular_model.predict(X_test)\n",
    "\n",
    "# Create datasets with predictions\n",
    "test_regular = test_data_with_clusters.copy()\n",
    "test_regular['prediction'] = regular_preds\n",
    "\n",
    "test_fair = test_data_with_clusters.copy()\n",
    "test_fair['prediction'] = y_pred\n",
    "\n",
    "# Calculate CMI for both prediction sets\n",
    "print(\"Evaluating mitigation effectiveness...\")\n",
    "regular_cmi = calculate_cmi(\n",
    "    test_regular,\n",
    "    test_clusters,\n",
    "    sensitive_columns,\n",
    "    'prediction',\n",
    "    nonsensitive_columns\n",
    ")\n",
    "\n",
    "fair_cmi = calculate_cmi(\n",
    "    test_fair,\n",
    "    test_clusters,\n",
    "    sensitive_columns,\n",
    "    'prediction',\n",
    "    nonsensitive_columns\n",
    ")\n",
    "\n",
    "print(f\"CMI on regular predictions: {regular_cmi:.4f}\")\n",
    "print(f\"CMI on fair predictions: {fair_cmi:.4f}\")\n",
    "print(f\"CMI reduction: {(1 - fair_cmi/regular_cmi)*100:.2f}%\")\n",
    "\n",
    "# Calculate accuracy\n",
    "regular_acc = accuracy_score(y_test, regular_preds)\n",
    "fair_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Regular model accuracy: {regular_acc:.4f}\")\n",
    "print(f\"Fair model accuracy: {fair_acc:.4f}\")\n",
    "print(f\"Accuracy change: {(fair_acc - regular_acc)*100:+.2f}%\")\n",
    "\n",
    "# Calculate CMI per cluster\n",
    "regular_cmi_per_cluster = calculate_cmi_per_cluster(\n",
    "    test_regular,\n",
    "    test_clusters,\n",
    "    sensitive_columns,\n",
    "    'prediction',\n",
    "    nonsensitive_columns\n",
    ")\n",
    "\n",
    "fair_cmi_per_cluster = calculate_cmi_per_cluster(\n",
    "    test_fair,\n",
    "    test_clusters,\n",
    "    sensitive_columns,\n",
    "    'prediction',\n",
    "    nonsensitive_columns\n",
    ")\n",
    "\n",
    "# Compare CMI reduction across clusters\n",
    "print(\"\\nCMI reduction by cluster:\")\n",
    "for cluster in sorted(regular_cmi_per_cluster.keys()):\n",
    "    if cluster in fair_cmi_per_cluster:\n",
    "        reg_cmi = regular_cmi_per_cluster[cluster]\n",
    "        fair_cmi = fair_cmi_per_cluster[cluster]\n",
    "        reduction = (1 - fair_cmi/reg_cmi)*100\n",
    "        print(f\"  Cluster {cluster}: {reg_cmi:.4f} -> {fair_cmi:.4f} ({reduction:.2f}% reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Conclusions\n",
    "Let's summarize our findings and draw conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Discrimination Detection Analysis:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimal_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[155], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a summary of our findings\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary of Discrimination Detection Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Optimal number of clusters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimal_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Best algorithm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. Overall CMI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcmi_values[best_algorithm]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimal_k' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a summary of our findings\n",
    "print(\"Summary of Discrimination Detection Analysis:\")\n",
    "print(f\"1. Optimal number of clusters: {optimal_k}\")\n",
    "print(f\"2. Best algorithm: {best_algorithm}\")\n",
    "print(f\"3. Overall CMI: {cmi_values[best_algorithm]:.4f}\")\n",
    "print(f\"4. High discrimination clusters: {high_discrim_clusters}\")\n",
    "\n",
    "if high_discrim_clusters:\n",
    "    # Get highest contributing attribute for each high-discrimination cluster\n",
    "    for cluster_id in high_discrim_clusters:\n",
    "        cluster_data = train_data_with_clusters[train_data_with_clusters['cluster'] == cluster_id]\n",
    "        \n",
    "        contributions = hierarchical_cmi_decomposition(\n",
    "            cluster_data,\n",
    "            np.zeros(len(cluster_data)),\n",
    "            sensitive_columns,\n",
    "            outcome_column,\n",
    "            nonsensitive_columns\n",
    "        )\n",
    "        \n",
    "        main_contributor = max(contributions.items(), key=lambda x: x[1])[0]\n",
    "        print(f\"5. Cluster {cluster_id} main contributor: {main_contributor}\")\n",
    "        \n",
    "        if len(sensitive_columns) >= 2:\n",
    "            interaction = interaction_information(\n",
    "                cluster_data,\n",
    "                np.zeros(len(cluster_data)),\n",
    "                sensitive_columns[0],\n",
    "                sensitive_columns[1],\n",
    "                outcome_column,\n",
    "                nonsensitive_columns\n",
    "            )\n",
    "            \n",
    "            effect_type = \"Synergistic\" if interaction > 0 else \"Redundant\"\n",
    "            print(f\"6. {effect_type} effect between {sensitive_columns[0]} and {sensitive_columns[1]}\")\n",
    "\n",
    "print(f\"7. Mitigation: {(1 - fair_cmi/regular_cmi)*100:.2f}% CMI reduction with {(fair_acc - regular_acc)*100:+.2f}% accuracy change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis reveals hidden patterns of discrimination in the Adult dataset that might not be evident from simple aggregate statistics. By using the clustering-based approach with Conditional Mutual Information, we identified specific clusters where discrimination is more pronounced.\n",
    "Our mitigation strategies successfully reduced this discrimination while maintaining prediction accuracy. The results demonstrate that it's possible to develop fairer automated decision-making systems without compromising performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
